{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB web scraper\n",
    "### Scrape all movies released between 1980 - 2016\n",
    "\n",
    "Feature Film, Released between 1970-01-01 and 2023-04-30 in the United States (sorted by Release Date, descending)\n",
    "\n",
    "80,556 titles are returned and 100 titles are displayed on each page = 856 pages to scrape (loop)\n",
    "\n",
    "https://www.imdb.com/search/title/?title_type=feature&release_date=1970-01-01%2C2023-04-30&countries=us&sort=release_date,desc&count=100&start=1\n",
    "\n",
    "The start parameter referes to teh movie # in the search results - increase by 100 each loop.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the terminal, cd into the correct directory\n",
    "1. python3 -m venv ./venv\n",
    "2. source ./venv/bin/activate\n",
    "3. pip install pandas\n",
    "4. pip install bs4\n",
    "5. pip install requests\n",
    "6. pip install jupyter notebook\n",
    "\n",
    "Run using:\n",
    "jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/search/title/?title_type=feature&release_date=1970-01-01%2C2023-04-30&countries=us&sort=release_date,desc&count=100&start='\n",
    "\n",
    "headers ={\n",
    "  'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.imdb.com/search/title/?title_type=feature&release_date=1970-01-01%2C2023-04-30&countries=us&sort=release_date,desc&count=100&start=1\n",
      "Waiting 1 seconds to scrape \n",
      " https://www.imdb.com/search/title/?title_type=feature&release_date=1970-01-01%2C2023-04-30&countries=us&sort=release_date,desc&count=100&start=1\n",
      "page #1 scraping is done.\n",
      "https://www.imdb.com/search/title/?title_type=feature&release_date=1970-01-01%2C2023-04-30&countries=us&sort=release_date,desc&count=100&start=101\n",
      "Waiting 6 seconds to scrape \n",
      " https://www.imdb.com/search/title/?title_type=feature&release_date=1970-01-01%2C2023-04-30&countries=us&sort=release_date,desc&count=100&start=101\n",
      "page #2 scraping is done.\n",
      "https://www.imdb.com/search/title/?title_type=feature&release_date=1970-01-01%2C2023-04-30&countries=us&sort=release_date,desc&count=100&start=201\n",
      "Waiting 5 seconds to scrape \n",
      " https://www.imdb.com/search/title/?title_type=feature&release_date=1970-01-01%2C2023-04-30&countries=us&sort=release_date,desc&count=100&start=201\n",
      "page #3 scraping is done.\n",
      "       _id               movie_title  year mpaa_rating runtime   \n",
      "0  1000001                   Journey  II)                  120  \\\n",
      "1  1000002     Curse of the Weredeer  2023     Unrated           \n",
      "2  1000003             It's All True  2023   Not Rated      53   \n",
      "3  1000004  The Long Hollywood Night  2023                  89   \n",
      "4  1000005        Kisses and Bullets  2023                  69   \n",
      "\n",
      "                   genre rating metascore   \n",
      "0                  Drama                   \\\n",
      "1         Comedy, Horror                    \n",
      "2  Drama, Music, Musical                    \n",
      "3  Crime, Drama, Mystery                    \n",
      "4           Crime, Drama                    \n",
      "\n",
      "                                             summary                 director   \n",
      "0  Roberto is a young man who is trying to find h...    Cristopher Rodriguez   \\\n",
      "1  There's sumthin' in them woods, 'n it's killin...             Ben Johnson    \n",
      "2  A story about personal death, rebirth, mental ...  Malinda Kathleen Reese    \n",
      "3  A lounge singer and a screenwriter attempt to ...         Joss Refauvelet    \n",
      "4  An Internet model and her roommates invite men...       John K. Eagle Jr.    \n",
      "\n",
      "                                               stars votes   \n",
      "0  Meaghan Martin, Rafael Cebrián, Arcelia Ramíre...    24  \\\n",
      "1  Lloyd Kaufman, Jessa Flux, Nadia White, Alyss ...         \n",
      "2               Malinda Kathleen Reese, Kyana Fanene         \n",
      "3  Devereau Chumrau, Ryan Willer, Heidi Rhodes, G...         \n",
      "4  Aaron Bias, Mercedes Davis, Antawn Ivey, Terre...         \n",
      "\n",
      "  gross_revenue_us_canada                                           imdb_url   \n",
      "0                          https://www.imdb.com/title/tt4565764/?ref_=adv...  \\\n",
      "1                          https://www.imdb.com/title/tt15035270/?ref_=ad...   \n",
      "2                          https://www.imdb.com/title/tt27350731/?ref_=ad...   \n",
      "3                          https://www.imdb.com/title/tt14506482/?ref_=ad...   \n",
      "4                          https://www.imdb.com/title/tt27667802/?ref_=ad...   \n",
      "\n",
      "                                           image_url  \n",
      "0  https://m.media-amazon.com/images/M/MV5BZDhmYW...  \n",
      "1  https://m.media-amazon.com/images/M/MV5BNzlkOW...  \n",
      "2  https://m.media-amazon.com/images/M/MV5BZWJhZD...  \n",
      "3  https://m.media-amazon.com/images/M/MV5BM2MxNG...  \n",
      "4  https://m.media-amazon.com/images/S/sash/NapCx...  \n"
     ]
    }
   ],
   "source": [
    "# https://github.com/SkeyRahaman/Web-Scraping-for-IMDb-top-250-movies-details/blob/master/Web%20Scraping.ipynb\n",
    "def director_and_actor(director_and_star):\n",
    "    director_and_star =  director_and_star.replace(\"\\n\",\"\")\n",
    "    director_and_star = director_and_star.replace(\"|\",\"\")\n",
    "    director_and_star = director_and_star.split(\"Stars:\")\n",
    "    director_and_star[0] = director_and_star[0].replace(\"Director:\",\"\")\n",
    "    director_and_star[0] = director_and_star[0].replace(\"Directors:\",\"\")\n",
    "    for i in range(10):\n",
    "        director_and_star[0]=director_and_star[0].replace(\"  \",\" \")\n",
    "    director = director_and_star[0]\n",
    "    stars = director_and_star[1]\n",
    "    stars = stars.replace(\":\",\"\")\n",
    "    return director,stars\n",
    "\n",
    "\n",
    "wait_between_pages = 1\n",
    "start = 1\n",
    "\n",
    "_id = 1000000\n",
    "\n",
    "imdb_df = pd.DataFrame(columns=[\"_id\", \"movie_title\", \"year\", \"mpaa_rating\", \"runtime\", \"genre\", \"rating\", \"metascore\", \"summary\", \"director\", \"stars\", \"votes\", \"gross_revenue_us_canada\", \"imdb_url\", \"image_url\"])\n",
    "\n",
    "for page in range(1, 4):  #loop into the page (856 total = range 1, 857)\n",
    "\n",
    "    scrape_url = url + str(start)\n",
    "    print (scrape_url)\n",
    "    \n",
    "    time.sleep(wait_between_pages)\n",
    "    \n",
    "    print(f\"Waiting {wait_between_pages} seconds to scrape \\n {scrape_url}\" )\n",
    "    \n",
    "    html_text = requests.get(scrape_url, headers=headers).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")    \n",
    "    # print(soup)\n",
    "        \n",
    "    for movie_item in soup.find_all(class_='lister-item'):\n",
    "        \n",
    "        _id+=1\n",
    "        \n",
    "        movie_title = movie_item.find(class_='lister-item-header').a.text\n",
    "        try:\n",
    "            year = movie_item.find(class_='lister-item-year').text[1:5]\n",
    "            if year == \"I) (\":\n",
    "                year = movie_item.find(class_='lister-item-year').text[5:9] \n",
    "        except:\n",
    "            year = \"\"\n",
    "\n",
    "        try:\n",
    "            mpaa_rating = movie_item.find(class_='certificate').text\n",
    "        except:\n",
    "            mpaa_rating = \"\"\n",
    "\n",
    "        try:\n",
    "            runtime = movie_item.find(class_='runtime').text\n",
    "            runtime = runtime.replace(\"min\", \"\")\n",
    "            runtime = runtime.strip()\n",
    "        except:\n",
    "            runtime = \"\"\n",
    "\n",
    "        try:\n",
    "            genre = movie_item.find(class_='genre').text.strip()\n",
    "        except:\n",
    "            genre = \"\"\n",
    "\n",
    "        try:\n",
    "            rating = movie_item.find(class_='ipl-rating-star__rating').text\n",
    "        except:\n",
    "            rating = \"\"\n",
    "        \n",
    "        try:\n",
    "            metascore = movie_item.find(class_='metascore').text\n",
    "        except:\n",
    "            metascore = \"\"\n",
    "        \n",
    "        try:\n",
    "            summary = movie_item.find(class_='lister-item-content').select('p')[1].text.strip()\n",
    "        except:\n",
    "            summary = \"\"\n",
    "        \n",
    "        try:\n",
    "            #directors_stars = movie_item.find(class_='lister-item-content').select('p')[2].text.strip()\n",
    "            director, stars = director_and_actor(movie_item.find(class_='lister-item-content').select('p')[2].text.strip())\n",
    "        except:\n",
    "            directors_stars = \"\"\n",
    "\n",
    "        try:\n",
    "            votes = movie_item.find(class_='lister-item-content').select('p')[3].select('span')[1].text\n",
    "        except:\n",
    "            votes = \"\"\n",
    "\n",
    "        try:\n",
    "            gross_revenue_us_canada = movie_item.find(class_='lister-item-content').select('p')[3].select('span')[4]['data-value']\n",
    "            gross_revenue_us_canada = gross_revenue_us_canada.replace(\"$\", \"\")\n",
    "            gross_revenue_us_canada = gross_revenue_us_canada (\",\", \"\")\n",
    "            gross_revenue_us_canada = gross_revenue_us_canada.strip()\n",
    "        except:\n",
    "            gross_revenue_us_canada = \"\"\n",
    "            \n",
    "        try:\n",
    "            imdb_url = 'https://www.imdb.com' + movie_item.find(class_='lister-item-content').find(class_='lister-item-header').a['href']\n",
    "        except:\n",
    "            imdb_url = \"\"\n",
    "        \n",
    "        try:\n",
    "            image_url = movie_item.find(\"div\", class_='lister-item-image').a.img['loadlate']\n",
    "        except:\n",
    "            image_url = \"\"\n",
    "            \n",
    "        \n",
    "        row = pd.Series(data=\n",
    "        {\n",
    "            \"_id\": _id,\n",
    "            \"movie_title\": movie_title,\n",
    "            \"year\": year,\n",
    "            \"mpaa_rating\": mpaa_rating,\n",
    "            \"runtime\": runtime,\n",
    "            \"genre\": genre,\n",
    "            \"rating\": rating,\n",
    "            \"metascore\": metascore,\n",
    "            \"summary\": summary,\n",
    "            \"director\": director,\n",
    "            \"stars\": stars,\n",
    "            \"votes\": votes,\n",
    "            \"gross_revenue_us_canada\": gross_revenue_us_canada,\n",
    "            \"imdb_url\": imdb_url,\n",
    "            \"image_url\": image_url\n",
    "        })\n",
    "        imdb_df = pd.concat([imdb_df, row.to_frame().T], axis=0, ignore_index = True)\n",
    "\n",
    "        #print(_id)\n",
    "        #print(movie_title)\n",
    "        #print(year)\n",
    "        #print(mpaa_rating)\n",
    "        #print(runtime)\n",
    "        #print(genre)\n",
    "        #print(rating)\n",
    "        #print(metascore)\n",
    "        #print(summary)\n",
    "        #print(director)\n",
    "        #print(stars)\n",
    "        #print(votes)\n",
    "        #print(gross)\n",
    "        #print(imdb_url)\n",
    "        #print(image_url)\n",
    "          \n",
    "        #print( '\\n', '----', '\\n')\n",
    "\n",
    "\n",
    "    #print(\"\\n\")\n",
    "    print(f\"page #{page} scraping is done.\")    \n",
    "    wait_between_pages = random.randint(3, 9)\n",
    "    \n",
    "    start = start + 100\n",
    "    \n",
    "        \n",
    "print(imdb_df.head())\n",
    "imdb_df.to_csv(\"./imdb_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get movie details from the details pages.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000001\n",
      "1000002\n",
      "1000003\n",
      "1000004\n",
      "1000005\n",
      "1000006\n",
      "1000007\n",
      "1000008\n",
      "1000009\n",
      "1000010\n",
      "1000011\n",
      "1000012\n",
      "1000013\n",
      "1000014\n",
      "1000015\n",
      "1000016\n",
      "1000017\n",
      "1000018\n",
      "1000019\n",
      "1000020\n",
      "1000021\n",
      "1000022\n",
      "1000023\n",
      "1000024\n",
      "1000025\n",
      "1000026\n",
      "1000027\n",
      "1000028\n",
      "1000029\n",
      "1000030\n",
      "1000031\n",
      "1000032\n",
      "1000033\n",
      "1000034\n",
      "1000035\n",
      "1000036\n",
      "1000037\n",
      "1000038\n",
      "1000039\n",
      "1000040\n",
      "1000041\n",
      "1000042\n",
      "1000043\n",
      "1000044\n",
      "1000045\n",
      "1000046\n",
      "1000047\n",
      "1000048\n",
      "1000049\n",
      "1000050\n",
      "1000051\n",
      "1000052\n",
      "1000053\n",
      "1000054\n",
      "1000055\n",
      "1000056\n",
      "1000057\n",
      "1000058\n",
      "1000059\n",
      "1000060\n",
      "1000061\n",
      "1000062\n",
      "1000063\n",
      "1000064\n",
      "1000065\n",
      "1000066\n",
      "1000067\n",
      "1000068\n",
      "1000069\n",
      "1000070\n",
      "1000071\n",
      "1000072\n",
      "1000073\n",
      "1000074\n",
      "1000075\n",
      "1000076\n",
      "1000077\n",
      "1000078\n",
      "1000079\n",
      "1000080\n",
      "1000081\n",
      "1000082\n",
      "1000083\n",
      "1000084\n",
      "1000085\n",
      "1000086\n",
      "1000087\n",
      "1000088\n",
      "1000089\n",
      "1000090\n",
      "1000091\n",
      "1000092\n",
      "1000093\n",
      "1000094\n",
      "1000095\n",
      "1000096\n",
      "1000097\n",
      "1000098\n",
      "1000099\n",
      "1000100\n",
      "1000101\n",
      "1000102\n",
      "1000103\n",
      "1000104\n",
      "1000105\n",
      "1000106\n",
      "1000107\n",
      "1000108\n",
      "1000109\n",
      "1000110\n",
      "1000111\n",
      "1000112\n",
      "1000113\n",
      "1000114\n",
      "1000115\n",
      "1000116\n",
      "1000117\n",
      "1000118\n",
      "1000119\n",
      "1000120\n",
      "1000121\n",
      "1000122\n",
      "1000123\n",
      "1000124\n",
      "1000125\n",
      "1000126\n",
      "1000127\n",
      "1000128\n",
      "1000129\n",
      "1000130\n",
      "1000131\n",
      "1000132\n",
      "1000133\n",
      "1000134\n",
      "1000135\n",
      "1000136\n",
      "1000137\n",
      "1000138\n",
      "1000139\n",
      "1000140\n",
      "1000141\n",
      "1000142\n",
      "1000143\n",
      "1000144\n",
      "1000145\n",
      "1000146\n",
      "1000147\n",
      "1000148\n",
      "1000149\n",
      "1000150\n",
      "1000151\n",
      "1000152\n",
      "1000153\n",
      "1000154\n",
      "1000155\n",
      "1000156\n",
      "1000157\n",
      "1000158\n",
      "1000159\n",
      "1000160\n",
      "1000161\n",
      "1000162\n",
      "1000163\n",
      "1000164\n",
      "1000165\n",
      "1000166\n",
      "1000167\n",
      "1000168\n",
      "1000169\n",
      "1000170\n",
      "1000171\n",
      "1000172\n",
      "1000173\n",
      "1000174\n",
      "1000175\n",
      "1000176\n",
      "1000177\n",
      "1000178\n",
      "1000179\n",
      "1000180\n",
      "1000181\n",
      "1000182\n",
      "1000183\n",
      "1000184\n",
      "1000185\n",
      "1000186\n",
      "1000187\n",
      "1000188\n",
      "1000189\n",
      "1000190\n",
      "1000191\n",
      "1000192\n",
      "1000193\n",
      "1000194\n",
      "1000195\n",
      "1000196\n",
      "1000197\n",
      "1000198\n",
      "1000199\n",
      "1000200\n",
      "1000201\n",
      "1000202\n",
      "1000203\n",
      "1000204\n",
      "1000205\n",
      "1000206\n",
      "1000207\n",
      "1000208\n",
      "1000209\n",
      "1000210\n",
      "1000211\n",
      "1000212\n",
      "1000213\n",
      "1000214\n",
      "1000215\n",
      "1000216\n",
      "1000217\n",
      "1000218\n",
      "1000219\n",
      "1000220\n",
      "1000221\n",
      "1000222\n",
      "1000223\n",
      "1000224\n",
      "1000225\n",
      "1000226\n",
      "1000227\n",
      "1000228\n",
      "1000229\n",
      "1000230\n",
      "1000231\n",
      "1000232\n",
      "1000233\n",
      "1000234\n",
      "1000235\n",
      "1000236\n",
      "1000237\n",
      "1000238\n",
      "1000239\n",
      "1000240\n",
      "1000241\n",
      "1000242\n",
      "1000243\n",
      "1000244\n",
      "1000245\n",
      "1000246\n",
      "1000247\n",
      "1000248\n",
      "1000249\n",
      "1000250\n",
      "1000251\n",
      "1000252\n",
      "1000253\n",
      "1000254\n",
      "1000255\n",
      "1000256\n",
      "1000257\n",
      "1000258\n",
      "1000259\n",
      "1000260\n",
      "1000261\n",
      "1000262\n",
      "1000263\n",
      "1000264\n",
      "1000265\n",
      "1000266\n",
      "1000267\n",
      "1000268\n",
      "1000269\n",
      "1000270\n",
      "1000271\n",
      "1000272\n",
      "1000273\n",
      "1000274\n",
      "1000275\n",
      "1000276\n",
      "1000277\n",
      "1000278\n",
      "1000279\n",
      "1000280\n",
      "1000281\n",
      "1000282\n",
      "1000283\n",
      "1000284\n",
      "1000285\n",
      "1000286\n",
      "1000287\n",
      "1000288\n",
      "1000289\n",
      "1000290\n",
      "1000291\n",
      "1000292\n",
      "1000293\n",
      "1000294\n",
      "1000295\n",
      "1000296\n",
      "1000297\n",
      "1000298\n",
      "1000299\n",
      "1000300\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "#movie_detail_page = requests.get(scrape_url, headers=headers).text\n",
    "#detail_soup = BeautifulSoup(movie_detail_page, \"html.parser\")         \n",
    "#popularity_score = movie_item.find(class_='lister-item-header').a.text        \n",
    "#hero-rating-bar__popularity__score\n",
    "\n",
    "# Read the IMDb data from the CSV file\n",
    "imdb_data = pd.read_csv('imdb_data.csv')\n",
    "\n",
    "# Create an empty DataFrame to store the IMDb details\n",
    "imdb_details = pd.DataFrame(columns=['_id', 'popularity_score', 'release_date_us', 'estimated_budget', 'opening_weekend_domestic_date', 'opening_weekend_domestic_gross', 'worldwide_gross' ])\n",
    "\n",
    "# Loop through each row in the IMDb data\n",
    "for index, row in imdb_data.iterrows():\n",
    "    _id = row['_id']\n",
    "    imdb_url = row['imdb_url']\n",
    "    \n",
    "    print(_id)\n",
    "    \n",
    "    # Open the IMDb URL and parse the page with Beautiful Soup\n",
    "    #response = requests.get(imdb_url)\n",
    "    #soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    time.sleep(random.randint(3, 9))\n",
    "    \n",
    "    details_page_text = requests.get(imdb_url, headers=headers).text\n",
    "    \n",
    "    details_soup = BeautifulSoup(details_page_text, \"html.parser\")\n",
    "    \n",
    "\n",
    "    # popularity_score\n",
    "    try:\n",
    "        popularity_score = details_soup.find(\"div\", attrs={\"data-testid\":\"hero-rating-bar__popularity__score\" }).text\n",
    "    except:\n",
    "        popularity_score = \"\"\n",
    "    \n",
    "    # release date\n",
    "    try:\n",
    "        release_date_us = details_soup.find('li', attrs={'data-testid':'title-details-releasedate'}).find('li', class_='ipc-inline-list__item').text\n",
    "        release_date_us = release_date_us.replace(\"(United States)\", \"\")\n",
    "        release_date_us = release_date_us.strip()\n",
    "    except:\n",
    "        release_date_us = \"\"\n",
    "    \n",
    "    # estimated budget\n",
    "    try:\n",
    "        estimated_budget = details_soup.find('li', attrs={'data-testid':'title-boxoffice-budget'}).text\n",
    "        estimated_budget = estimated_budget.replace(\"Budget\",\"\")\n",
    "        estimated_budget = estimated_budget.replace(\"(estimated)\",\"\")\n",
    "        estimated_budget = estimated_budget.replace(\"$\",\"\")\n",
    "        estimated_budget = estimated_budget.replace(\",\",\"\")\n",
    "        estimated_budget = estimated_budget.strip()\n",
    "    except:\n",
    "        estimated_budget = \"\"\n",
    "    \n",
    "    # opening weekend domestic gross (us & canada)\n",
    "    try:\n",
    "        opening_weekend_domestic_gross = details_soup.find('li', attrs={'data-testid':'title-boxoffice-openingweekenddomestic'}).select('span', class_='ipc-metadata-list-item__list-content-item')[1].text\n",
    "        opening_weekend_domestic_gross = opening_weekend_domestic_gross.replace(\"$\", \"\")\n",
    "        opening_weekend_domestic_gross = opening_weekend_domestic_gross.replace(\",\", \"\")\n",
    "        opening_weekend_domestic_gross = opening_weekend_domestic_gross.strip()\n",
    "    except:\n",
    "        opening_weekend_domestic_gross = \"\"\n",
    "    \n",
    "    # opening weekend date (us & canada)\n",
    "    try:\n",
    "        opening_weekend_domestic_date = details_soup.find('li', attrs={'data-testid':'title-boxoffice-openingweekenddomestic'}).select('span', class_='ipc-metadata-list-item__list-content-item')[2].text\n",
    "    except:\n",
    "        opening_weekend_domestic_date = \"\"\n",
    "    \n",
    "    # worldwide gross\n",
    "    try:\n",
    "        worldwide_gross = details_soup.find('li', attrs={'data-testid':'title-boxoffice-cumulativeworldwidegross'}).find('span', class_='ipc-metadata-list-item__list-content-item').text\n",
    "        worldwide_gross = worldwide_gross.replace(\"$\", \"\")\n",
    "        worldwide_gross = worldwide_gross.replace(\",\", \"\")\n",
    "        worldwide_gross = worldwide_gross.strip()\n",
    "    except:\n",
    "        worldwide_gross = \"\"\n",
    "    \n",
    "    #print(_id)\n",
    "    #print(popularity_score)\n",
    "    #print(release_date_us)\n",
    "    #print(f'estimated budget: {estimated_budget}')\n",
    "    #print(f'domestic opening weekend date: {opening_weekend_domestic_date}')\n",
    "    #print(f'domestic opening weekend gross: {opening_weekend_domestic_gross}')\n",
    "    #print(f'worldwide gross: {worldwide_gross}')\n",
    "    \n",
    "    \n",
    "    # Append the details to the IMDb details DataFrame\n",
    "    #imdb_details = imdb_details.append({'_id': _id, 'popularity_score': popularity}, ignore_index=True)\n",
    "    imdb_details.loc[index] = [_id, popularity_score, release_date_us, estimated_budget, opening_weekend_domestic_date, opening_weekend_domestic_gross, worldwide_gross]\n",
    "    \n",
    "# Write the IMDb details to a new CSV file\n",
    "imdb_details.to_csv('imdb_details.csv', index=False)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape directors and stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
